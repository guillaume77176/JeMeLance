{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d749e879",
   "metadata": {},
   "source": [
    "# I - Script de la partie \"Récupération des données\". \n",
    "\n",
    "# I.1 -  Récupération massive du Registre Nationale des Entreprises de l'Inpi :\n",
    "\n",
    "\n",
    "Ce NoteBook constitue la première partie du processus de récupération des données. Pour récupérer les données d'informations et d'identification des entreprises francaises, deux choix en open data s'offrent à nous : \n",
    "- $i$) `la base Sirene proposée et maintenue par l'Insee` \n",
    "- $ii$) `la base du registre nationale des entreprises (RNE) proposé en accès libre et maintenue par l'Inpi`\n",
    "\n",
    "Nous avons besoin d'informations concernant la possible radiation ou non d'une entreprise donné, de la nature de l'activité de l'établissement principal, des établissements secondaires, de l'âge du/des dirigeant, de leurs expériences en entreprenariat, etc. \n",
    "La base Sirene, bien que complète du point de vue d'informations primaires, telles la cessation ou la nature des activités, n'est pas adaptée à notre problème.\n",
    "A l'inverse, la base RNE est idéale : elle contient bien plus d'information que la base Sirene. \n",
    "\n",
    "Nous allons donc récupérer la base RNE. Nous voulons récupérer dans un premier temps, de manière massive, l'ensemble des entreprises créees dans les secteurs du commerce, artisanat et artisanat réglementé, et cela pour la période couvrant 1980 - 2024.\n",
    "\n",
    "### Deux moyens sont proposés par l'Inpi pour récupérer cette base : \n",
    "\n",
    "- Le premier est la fourniture d'une `API` simple, dont vous trouverez une documentation complète en cliquant sur le lien \n",
    "suivant : https://www.inpi.fr/sites/default/files/2025-06/documentation%20technique%20API%20formalit%C3%A9s_v4.0.pdf.\n",
    "Les mises à jours sont quotidiennes.\n",
    "Un appel par le biais de cette API donne un ou plusieurs résultats au format json. \n",
    "La description détaillé de l'arboressance des json est détaillé ici : https://www.inpi.fr/sites/default/files/2025-06/Dictionnaire_de_donnees_INPI_2025_05_09.xlsx.\n",
    "Ce moyen est parfait pour récupérer des données de manière ponctuelle. Elle n'est donc pas vraiment adaptée à notre problème, bien qu'elle pourra servir à l'avenir.\n",
    "En effet, elle limite l'accès à 10 000 résultats par pages, avec des requêtes ne pouvant répondre plus de 100 résultats. Ce qui limite grandement les marches de manoeuvres pour \n",
    "une récupération massive, sachant que la création d'entreprise n'a fait que de croître ces dernières années.\n",
    "\n",
    "- Le second est la fourniture d'un accès ouvert au serveur `FTP` (File Transfer Protocol) mis à disposition par l'Inpi. Celui-çi donne accès à la base complète des formalités RNE et est mis à jour sur une fréquence qui semble mensuelle (cette information n'est pas disponible explicitement sur le site de l'Inpi, mais est présente dans les informations du fichier RNE du serveur ,voire plus loin). L'avantage de cette méthode est qu'elle permet de récupérer massivement l'ensemble de la base en téléchargeant simplement celle-çi. Cependant, la volumétrie des données est énorme : plus de 130 gb une fois le fichier (compressé) décompressé. Il faudra donc prendre cela en compte dans la récupération.\n",
    "Vous trouverez une documentation à l'adresse suivante : https://data.inpi.fr/content/editorial/Serveur_ftp_entreprises.\n",
    "\n",
    "Nous choisissons donc la deuxième méthode pour une récupération massive.\n",
    "\n",
    "Dans tous les cas, bien que ouverts, `les accès nécessitent la création d'un compte Inpi` à l'adresse suivante : \n",
    "https://data.inpi.fr/register.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a690f42",
   "metadata": {},
   "source": [
    "## I.1.1 - Stratégie de récupération et de stockage\n",
    "Par simplicité et reproductibilité, nous téléchargeons directement la base RNE depuis le serveur FTP mis à disposition par l'Inpi directement vers un dossier \"diffusion\" public du ssp cloud S3. Puis nous traitons en streaming la récupération de l'arborescence de chaque fichier json présent dans le fichier zip téléchargé, et nous importons 13 fichiers aux formats parquet directement dans un dossier \"data_RNE\", lui même sous-dossier de \"diffusion\", et donc accessible publiquement.\n",
    "\n",
    "La stratégie est la suivante :\n",
    "\n",
    "- i) Nous téléchargeons d'abord la base de donnée grâce à la librairie ftplib permettant de communiquer avec le serveur FTP de l'Inpi. \n",
    "Attention : cette partie nécessitera la récupération de votre `Token` dédié sur le site de l'Inpi ainsi que vos identifiants Inpi. \n",
    "Nous utilisons la librairie getpass pour la sécurité du token et de l'identifiant. Le fichier obtenu est un fichier au format `zip`, stocké dans le ssp cloud S3.\n",
    "Le fichier originel compte plus de 10 000 json, eux-mêmes contenants de nombreuses formalités. La fonction  `getRNEfrom_FTP` permet cela de récupérer ces formalités.\n",
    "\n",
    "- ii) Une fois cette base récupérée, nous implémentons une fonction nommée `get_RNE_past` permettant une lecture de chaque fichier json et ainsi sélectionner les entreprises selon des critères de dates et de départements. Par défaut, nous récupérons les entreprises pour les secteurs suivants : ARTISANALE, ARTISANALE REGLEMENTEE , COMMERCIALE, sur lesquelles nous nous concentrerons.\n",
    "Nous utilisons la librairie zipfile pour cela, qui permet une lecture de chaque fichier sans décompresser le zip directement.\n",
    "Nous utilisons `yield` natif de python afin de ne pas utiliser de listes. `yield` permet de ne pas saturer la mémoire vive puisqu'au lieu de retourner une énorme liste de dictionnaire dans notre cas, cette fonctionnalité permet d'itérer directement sur la fonction elle-même, renvoyant ainsi pas à pas chaque dictionnaire.\n",
    "\n",
    "- iii) Il faut remonter l'arborescence de chaque dictionnaire. La fonction `get_RNE_DataFrame` permet cela. Pour une documentation et une visualisation complète de cette arborescence, nous vous renvoyons ici :https://www.inpi.fr/sites/default/files/2025-06/Dictionnaire_de_donnees_INPI_2025_05_09.xlsx. Nous obtenons ainsi par la suite, de manière assez laborieuse, 13 fichiers parquet. Les fichiers sont enregistrés directement sur le ssp cloud S3. \n",
    "Nous précisons ici que nous récupérons le maximum de variables possibles, tout en restant cohérent avec la visée de notre projet. Il ne s'agit pas ici d'une partie de traitement et de selection des variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6ddf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages utilisés\n",
    "import json\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from ftplib import FTP\n",
    "import getpass\n",
    "import os\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connexion à S3\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass.getpass()\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass.getpass()\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = getpass.getpass()\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-east-1'\n",
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
    "    key = os.environ[\"AWS_ACCESS_KEY_ID\"], \n",
    "    secret = os.environ[\"AWS_SECRET_ACCESS_KEY\"], \n",
    "    token = os.environ[\"AWS_SESSION_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39765576",
   "metadata": {},
   "source": [
    "## i) Téléchargement de la base RNE depuis le serveur FTP de l'Inpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ce51e",
   "metadata": {},
   "source": [
    "Comme pour l'utilisation de l'API RNE, il suffit de se créer un compte INPI et de demander une souscription à l'utilisation du serveur ftp RNE. Les identifiants sont données directement sur le site de l'INPI une fois connecté, dans l'espace Mon Compte puis mes services API. On utilise les librairies ftplib et zipfile natives de python pour récupérer les données. Il est à noté que les mises à jours ne sont pas quotidiennes contrairement à l'API RNE mais mensuelles.\n",
    "\n",
    "Doc : https://www.inpi.fr/sites/default/files/2025-06/documentation%20technique%20API_comptes_annuels%20v5.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91004225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdp/id Inpi ftp à rentrer \n",
    "username = getpass.getpass()\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRNEfrom_FTP(username : str, password : str, server_adress : str = \"www.inpi.net\") -> None:\n",
    "    \n",
    "     \"\"\"\n",
    "    Fonction permettant la connexion au serveur FTP de l'Inpi, affichant les fichiers disponibles, puis\n",
    "    téléchargeant le fichier des formalités RNE directement sur le ssp cloud S3.\n",
    "\n",
    "    Changer le nom du Bucket \"MY_BUCKET\" si besoin, ainsi que FILE_PATH_OUT_S3.\n",
    "\n",
    "     inputs : \n",
    "               - username : identifiant inpi\n",
    "               - password : mot de passe inpi\n",
    "               - server_adress : valeur par défaut = www.inpi.net\n",
    "     \n",
    "     outputs :\n",
    "               ne retourne pas d'objet\n",
    "     \n",
    "     \"\"\"\n",
    "     #Connexion au serveur FTP\n",
    "     ftp = FTP(server_adress)\n",
    "     ftp.login(user=username, passwd=password)\n",
    "\n",
    "     print(\"Connexion réussie à :\", server_adress)\n",
    "     print(\"Répertoire courant :\", ftp.pwd())\n",
    "     \n",
    "     #Pour afficher le répertoire\n",
    "     file_list = []\n",
    "     print(ftp.retrlines('LIST'))\n",
    "     \n",
    "     #Récupération du nom du fichier\n",
    "     ftp.retrlines('LIST',file_list.append)\n",
    "     file = file_list[-1][59:]\n",
    "     \n",
    "\n",
    "     #Upload du fichier zip sur S3 dans diffusion\n",
    "     MY_BUCKET = \"guillaume176\"\n",
    "     FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/diffusion/{file}\"\n",
    "\n",
    "     print(f\"Téléchargement de {file} et stockage dans S3\")\n",
    "     \n",
    "     #Téléchargement direct depuis le serveur ftp vers S3\n",
    "     with fs.open(FILE_PATH_OUT_S3, 'wb') as file_out:\n",
    "          ftp.retrbinary(f\"RETR {file}\", file_out.write)\n",
    "     \n",
    "\n",
    "     print(f\"Fichier '{file}' téléchargé avec succès\")\n",
    "\n",
    "     ftp.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2fc23b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion réussie à : www.inpi.net\n",
      "Répertoire courant : /\n",
      "-rw-r--r--    1 ftp      ftp      4078344770 Oct 21 14:14 stock_RNE_comptes_annuels_20250926_1000.zip\n",
      "-rw-r--r--    1 ftp      ftp      13708395381 Oct 13 10:09 stock_RNE_formalites_20250523_0000.zip\n",
      "226 Directory send OK.\n",
      "Téléchargement de stock_RNE_formalites_20250523_0000.zip et stockage dans S3\n",
      "Fichier 'stock_RNE_formalites_20250523_0000.zip' téléchargé avec succès\n"
     ]
    }
   ],
   "source": [
    "getRNEfrom_FTP(username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7f681",
   "metadata": {},
   "source": [
    "On vérifie que le fichier zip s'est bien télécharger dans le fichier diffusion (public) du ssp cloud S3 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c15943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['guillaume176/diffusion/.keep', 'guillaume176/diffusion/data_RNE', 'guillaume176/diffusion/stock_RNE_formalites_20250523_0000.zip']\n"
     ]
    }
   ],
   "source": [
    "path_diffusion = \"guillaume176/diffusion\"\n",
    "print(fs.ls(path_diffusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e830bb",
   "metadata": {},
   "source": [
    "## ii) Récupération du json pour les entreprises des secteurs commerciales, artisanales et artisanales réglementée, créées entre 1980 et 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7178d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_RNE_past(date_mini : list  ,date_maxi : list) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction permettant la lecture des fichiers json depuis le cloud ssp cloud S3 en selectionnant \n",
    "    intervalle de dates. Récupère les entreprises crées dans cet intervalle de dates pour l'ensemble du territoire Français.\n",
    "\n",
    "    Changer la liste act selon les besoins.\n",
    "\n",
    "     inputs : \n",
    "               - date_mini : borne inf incluse intervalle de dates type [year,month,day] = [2024,1,1]\n",
    "               - date_maxi : brone sup non-incluse intervalle de dates type [year,month,day] = [2025,8,2]\n",
    "     \n",
    "     outputs :\n",
    "               ne retourne pas d'objet explicite, mais chaque dictionnaire portant sur une firme \n",
    "               pas à pas grâce à la fonctionnalité yields\n",
    "     \n",
    "     \"\"\"\n",
    "    \n",
    "    #Liste des secteurs d'activités sur lesquels travailler\n",
    "    act = [\"ARTISANALE\",\"ARTISANALE_REGLEMENTEE\",\"COMMERCIALE\"]\n",
    "    \n",
    "    date_min = datetime.date(date_mini[0],date_mini[1],date_mini[2])\n",
    "    date_max = datetime.date(date_maxi[0],date_maxi[1],date_maxi[2])\n",
    "    \n",
    " \n",
    "    #Récupération du chemin du fichier zip enregistré précédemment depuis diffusion sur le ssp cloud S3\n",
    "    path = fs.ls(\"guillaume176/diffusion\")[-1]\n",
    "\n",
    "    \n",
    "    with fs.open(f\"s3://{path}\",\"rb\") as s3_file:\n",
    "        with zipfile.ZipFile(s3_file) as archive:\n",
    "            \n",
    "            for name in tqdm(archive.namelist()):\n",
    "                \n",
    "                with archive.open(name,mode=\"r\") as f:\n",
    "                    \n",
    "                    json_it = f.read().decode('utf-8')\n",
    "                json_it = json_it[:-1] + \"]\"  #Corrige ici un bug dû à une erreur de formatage native des fichiers json\n",
    "                json_it = json.loads(json_it)\n",
    "                \n",
    "                for firme in json_it:\n",
    "                    \n",
    "                    if firme.get(\"formality\").get(\"content\").get(\"natureCreation\").get(\"dateCreation\") is not None:\n",
    "                        \n",
    "                        dateCreation = firme.get(\"formality\").get(\"content\").get(\"natureCreation\").get(\"dateCreation\")\n",
    "                        dateCreation = datetime.datetime.strptime(dateCreation, \"%Y-%m-%d\").date()\n",
    "                        \n",
    "                        activitePrincipale = firme.get(\"formality\").get(\"content\").get(\"formeExerciceActivitePrincipale\",\"non-disp\")\n",
    "                        \n",
    "                        if activitePrincipale in act:\n",
    "                            if (dateCreation >= date_min) and (dateCreation < date_max):\n",
    "                                personneMorale = firme.get(\"formality\").get(\"content\").get(\"personneMorale\")\n",
    "                                personnePhysique = firme.get(\"formality\").get(\"content\").get(\"personnePhysique\")\n",
    "                                \n",
    "                                if (personneMorale is not None) or (personnePhysique is not None):\n",
    "                                    yield firme\n",
    "                                else:\n",
    "                                    continue\n",
    "                                        \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919f12b",
   "metadata": {},
   "source": [
    "## iii) Récupération des informations utiles en parcourant l'arborescence de chaque json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb71e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_RNE_Dict() -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction permettant la création du dictionnaire de travail pour la récupération des données et la mise sous forme\n",
    "    de data frame.\n",
    "\n",
    "    Changer variables_rne si besoins. Changer autre_... et associe_... si besoins.\n",
    "\n",
    "     inputs : \n",
    "               None\n",
    "     \n",
    "     outputs :\n",
    "               RNE : dictionnaire dont les clefs sont les variables retenues, à modifier/ajouter selon les besoins.\n",
    "               Voire documentation Inpi pour les variables présentes dans la base du RNE.\n",
    "     \n",
    "     \"\"\"\n",
    "    \n",
    "    RNE = {}\n",
    "\n",
    "    variables_rne = [\n",
    "        \"siren\", \"cessation\", \"date_creation\", \"etranger\", \"micro\", \"agricole\", \"eirl\",\n",
    "        \"code_postal\", \"codeInseeCommune\", \"voie\", \"typeVoie\", \"numVoie\",\n",
    "        \"dateRadiation\", \"dateEffet\", \"denomination\", \"formeJuridique\", \"codeAPE\",\n",
    "        \"dateImmat\", \"dateDebutAct\", \"personneMorale\", \"nicSiege\",\n",
    "        \"objet\", \"capitalVariable\", \"montantCapital\", \"formeExerciceActivitePrincipale\",\n",
    "        \"nom\", \"prenoms\", \"genre\", \"rolePourEntreprisePrincipal\",\"statutPourFormalitePrincipal\",\n",
    "        \"principalAPEPrincipal\",\"principalDateTransPrincipal\",\"indicateurDecesEntrepreneur\",\"dateCessationTotaleActivite\",\n",
    "        \"dateClotureLiquidation\",\"dateDissolutionDisparition\",\"indicateurCessationTemporaire\",\"indicateurPoursuiteActivite\",\n",
    "        \"indicateurMaintienImmatriculationRegistre\",\"indicateurDissolution\",\"indicateurDisparitionPM\",\"motifDisparition\",\n",
    "        \"dateMiseEnSommeil\",\"typeDissolution\",\"nb_autres\",\"diffusionINSEE\",\"diffusionCommerciale\",\"age_physique\"\n",
    "        \n",
    "                    ]\n",
    "\n",
    "\n",
    "    autre_ape = [f\"autre_{i}_ape\" for i in range(1,11)]\n",
    "    autre_statutFormalites = [f\"autre_{i}_statutFormalites\" for i in range(1,11)]\n",
    "    autre_role = [f\"autre_{i}_role\" for i in range(1,11)]\n",
    "    autre_adresse = [f\"autre_{i}_adresse\" for i in range(1,11)]\n",
    "    autre_datefin = [f\"autre_{i}_datefin\" for i in range(1,11)]\n",
    "    autre_dateeffetferm = [f\"autre_{i}_dateeffetferm\" for i in range(1,11)]\n",
    "    autre_datedebut = [f\"autre_{i}_datedebut\" for i in range(1,11)]\n",
    "    autre_dateeffettrans = [f\"autre_{i}_dateeffettrans\" for i in range(1,11)]\n",
    "    \n",
    "    associe_role = [f\"associe_{i}_role\" for i in range(1,6)]\n",
    "    associe_nom = [f\"associe_{i}_nom\" for i in range(1,6)]\n",
    "    associe_prenom = [f\"associe_{i}_prenom\" for i in range(1,6)]\n",
    "    associe_naissance = [f\"associe_{i}_naissance\" for i in range(1,6)]\n",
    "    associe_id = [f\"associe_{i}_id\" for i in range(1,6)]\n",
    "    \n",
    "    variables_rne.extend([*autre_ape,*autre_statutFormalites,*autre_role,*autre_adresse,*autre_datefin,*autre_dateeffetferm,\n",
    "                        *autre_datedebut,*autre_dateeffettrans,*associe_role,*associe_prenom,*associe_nom,*associe_id,*associe_naissance])\n",
    "    \n",
    "    for var in variables_rne:\n",
    "        RNE[var] = []  \n",
    "\n",
    "    return RNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd29ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_RNE_DataFrame(firme : dict) -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction permettant le parcours des arborescences d'un dictionnaire donné d'une firme donnée \n",
    "    dont la nomenclature est celle du RNE Inpi.\n",
    "\n",
    "    A adapter selon les cas en lien avec la fonction prepare_RNE_Dict().\n",
    "\n",
    "     inputs : \n",
    "               firme : dictionnaire issu d'un json RNE Inpi contenant l'aborescence d'une firme donnée\n",
    "     \n",
    "     outputs :\n",
    "               Enrichie RNE_ qui est une variable global\n",
    "     \n",
    "     \"\"\"\n",
    "    \n",
    "    #Dictionnaire de travail, externe à la fonction\n",
    "    global RNE_\n",
    "    \n",
    "    #Récupération des clefs itératives de RNE_\n",
    "    autre_ape = [f\"autre_{i}_ape\" for i in range(1,11)]\n",
    "    autre_statutFormalites = [f\"autre_{i}_statutFormalites\" for i in range(1,11)]\n",
    "    autre_role = [f\"autre_{i}_role\" for i in range(1,11)]\n",
    "    autre_adresse = [f\"autre_{i}_adresse\" for i in range(1,11)]\n",
    "    autre_datefin = [f\"autre_{i}_datefin\" for i in range(1,11)]\n",
    "    autre_dateeffetferm = [f\"autre_{i}_dateeffetferm\" for i in range(1,11)]\n",
    "    autre_datedebut = [f\"autre_{i}_datedebut\" for i in range(1,11)]\n",
    "    autre_dateeffettrans = [f\"autre_{i}_dateeffettrans\" for i in range(1,11)]\n",
    "    \n",
    "    associe_role = [f\"associe_{i}_role\" for i in range(1,6)]\n",
    "    associe_nom = [f\"associe_{i}_nom\" for i in range(1,6)]\n",
    "    associe_prenom = [f\"associe_{i}_prenom\" for i in range(1,6)]\n",
    "    associe_naissance = [f\"associe_{i}_naissance\" for i in range(1,6)]\n",
    "    associe_id = [f\"associe_{i}_id\" for i in range(1,6)]\n",
    "    \n",
    "    #Premiers get des json\n",
    "    formality = firme.get(\"formality\")\n",
    "    content = formality.get(\"content\")\n",
    "\n",
    "                  #########################################################################################\n",
    "            ######    Parcours des arborescences de chaque dictionnaire \"content\" pour une firme donnée    #######\n",
    "                  #########################################################################################\n",
    "    \n",
    "    # --- Informations générales indépendantes de personnes physiques ou morale ---\n",
    "    cessation = content.get(\"natureCessation\")\n",
    "    RNE_[\"cessation\"].append(1 if cessation else 0)\n",
    "    \n",
    "    RNE_[\"siren\"].append(formality.get(\"siren\"))\n",
    "    RNE_[\"date_creation\"].append(content.get(\"natureCreation\", {}).get(\"dateCreation\"))\n",
    "    RNE_[\"etranger\"].append(content.get(\"natureCreation\", {}).get(\"societeEtrangere\"))\n",
    "    RNE_[\"micro\"].append(content.get(\"natureCreation\", {}).get(\"microEntreprise\"))\n",
    "    RNE_[\"agricole\"].append(content.get(\"natureCreation\", {}).get(\"entrepriseAgricole\"))\n",
    "    RNE_[\"eirl\"].append(content.get(\"natureCreation\", {}).get(\"eirl\"))\n",
    "    RNE_[\"formeJuridique\"].append(content.get(\"natureCreation\", {}).get(\"formeJuridique\",\"non-disp\"))\n",
    "    \n",
    "    personneMorale = content.get(\"personneMorale\")\n",
    "    personnePhysique = content.get(\"personnePhysique\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # CAS 1 : PERSONNE MORALE\n",
    "    # ===================================================================\n",
    "    if personneMorale is not None:\n",
    "        RNE_[\"personneMorale\"].append(1)\n",
    "    \n",
    "        # --- Adresse ---\n",
    "        adresse = personneMorale.get(\"adresseEntreprise\", {}).get(\"adresse\", {})\n",
    "        RNE_[\"code_postal\"].append(adresse.get(\"codePostal\", \"non-disp\"))\n",
    "        RNE_[\"voie\"].append(adresse.get(\"voie\", \"non-disp\"))\n",
    "        RNE_[\"codeInseeCommune\"].append(adresse.get(\"codeInseeCommune\", \"non-disp\"))\n",
    "        RNE_[\"numVoie\"].append(adresse.get(\"numVoie\", \"non-disp\"))\n",
    "        RNE_[\"typeVoie\"].append(adresse.get(\"typeVoie\", \"non-disp\"))\n",
    "    \n",
    "        # --- Information sur la cessation si cessation ---\n",
    "        cessation_info = personneMorale.get(\"detailCessationEntreprise\", {})\n",
    "        RNE_[\"dateEffet\"].append(cessation_info.get(\"dateEffet\", \"non-disp\"))\n",
    "        RNE_[\"dateRadiation\"].append(cessation_info.get(\"dateRadiation\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDecesEntrepreneur\"].append(cessation_info.get(\"indicateurDecesEntrepreneur\", \"non-disp\"))\n",
    "        RNE_[\"dateCessationTotaleActivite\"].append(cessation_info.get(\"dateCessationTotaleActivite\", \"non-disp\"))\n",
    "        RNE_[\"dateClotureLiquidation\"].append(cessation_info.get(\"dateClotureLiquidation\", \"non-disp\"))\n",
    "        RNE_[\"dateDissolutionDisparition\"].append(cessation_info.get(\"dateDissolutionDisparition\", \"non-disp\"))\n",
    "        RNE_[\"indicateurCessationTemporaire\"].append(cessation_info.get(\"indicateurCessationTemporaire\", \"non-disp\"))\n",
    "        RNE_[\"indicateurPoursuiteActivite\"].append(cessation_info.get(\"indicateurPoursuiteActivite\", \"non-disp\"))\n",
    "        RNE_[\"indicateurMaintienImmatriculationRegistre\"].append(cessation_info.get(\"indicateurMaintienImmatriculationRegistre\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDissolution\"].append(cessation_info.get(\"indicateurDissolution\", \"non-disp\"))\n",
    "        RNE_[\"typeDissolution\"].append(cessation_info.get(\"typeDissolution\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDisparitionPM\"].append(cessation_info.get(\"indicateurDisparitionPM\", \"non-disp\"))\n",
    "        RNE_[\"motifDisparition\"].append(cessation_info.get(\"motifDisparition\", \"non-disp\"))\n",
    "        RNE_[\"dateMiseEnSommeil\"].append(cessation_info.get(\"dateMiseEnSommeil\", \"non-disp\"))\n",
    "        \n",
    "        # --- Information sur l'établissement principal si existence + historique (statutPourFormalitePrincipal) ---\n",
    "        principal = personneMorale.get(\"etablissementPrincipal\")\n",
    "        RNE_[\"rolePourEntreprisePrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"rolePourEntreprise\",\"non-disp\") if principal is not None else \"principal_false\")\n",
    "        RNE_[\"statutPourFormalitePrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"statutPourFormalite\",\"non-disp\") if principal is not None else \"principal_false\")\n",
    "        RNE_[\"principalAPEPrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"codeAPE\",\"non-disp\") if principal is not None else \"principal_false\")\n",
    "        RNE_[\"principalDateTransPrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"dateEffetTransfert\",\"non-disp\") if principal is not None else \"pincipal_false_transfert\")\n",
    "        \n",
    "        # --- Information sur les établissements secondaires si existence + historique ---\n",
    "        autres = personneMorale.get(\"autresEtablissements\")\n",
    "        if autres is not None:\n",
    "            \n",
    "            RNE_[\"nb_autres\"].append(len(autres))\n",
    "            \n",
    "            i = -1\n",
    "            for i in range(min(len(autres),10)):\n",
    "              \n",
    "                ape_autre = autre_ape[i]\n",
    "                statutFormalites_autre = autre_statutFormalites[i]\n",
    "                role_autre = autre_role[i]\n",
    "                adresse_autre = autre_adresse[i]\n",
    "                datefin_autre = autre_datefin[i]\n",
    "                dateeffetferm_autre = autre_dateeffetferm[i]\n",
    "                datedebut_autre = autre_datedebut[i]\n",
    "                dateeffettrans_autre = autre_dateeffettrans[i]\n",
    "                \n",
    "                RNE_[ape_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"codeApe\",\"non-disp\")\n",
    "                                              if autres[i].get(\"descriptionEtablissement\") else \"non-disp\")\n",
    "                \n",
    "                RNE_[statutFormalites_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"statutPourFormalite\",\"non-disp\")\n",
    "                                              if autres[i].get(\"descriptionEtablissement\") else \"non-disp\")\n",
    "                \n",
    "                RNE_[role_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"rolePourEntreprise\",\"non-disp\")\n",
    "                                              if autres[i].get(\"descriptionEtablissement\") else \"non-disp\")\n",
    "                \n",
    "                RNE_[adresse_autre].append(autres[i].get(\"adresse\").get(\"codePostal\",\"non-disp\")\n",
    "                                              if autres[i].get(\"adresse\") else \"non-disp\")\n",
    "                \n",
    "                RNE_[datedebut_autre].append(autres[i].get(\"activites\")[0].get(\"dateDebut\",\"non-disp\")\n",
    "                                              if len(autres[i].get(\"activites\")) > 0  else \"non-disp\")\n",
    "                \n",
    "                RNE_[datefin_autre].append(autres[i].get(\"activites\")[0].get(\"dateFin\",\"actif\") \n",
    "                                              if len(autres[i].get(\"activites\")) > 0 \n",
    "                                                    else \"non-disp\")\n",
    "                \n",
    "                RNE_[dateeffetferm_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"dateEffetFermeture\",\"non-disp\")\n",
    "                                              if autres[i].get(\"descriptionEtablissement\") else \"non-disp\")\n",
    "                \n",
    "                RNE_[dateeffettrans_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"dateEffetTransfert\",\"non-disp\")\n",
    "                                              if autres[i].get(\"descriptionEtablissement\") else \"non-disp\")\n",
    "                \n",
    "                \n",
    "            if -1 <= i < 9:\n",
    "                for j in range(i+1,10):\n",
    "                    \n",
    "                    ape_autre = autre_ape[j]\n",
    "                    statutFormalites_autre = autre_statutFormalites[j]\n",
    "                    role_autre = autre_role[j]\n",
    "                    adresse_autre = autre_adresse[j]\n",
    "                    datefin_autre = autre_datefin[j]\n",
    "                    dateeffetferm_autre = autre_dateeffetferm[j]\n",
    "                    datedebut_autre = autre_datedebut[j]\n",
    "                    dateeffettrans_autre = autre_dateeffettrans[j]\n",
    "                    \n",
    "                    \n",
    "                    RNE_[ape_autre].append(\"existence_null\")\n",
    "                    RNE_[statutFormalites_autre].append(\"existence_null\")\n",
    "                    RNE_[role_autre].append(\"existence_null\")\n",
    "                    RNE_[adresse_autre].append(\"existence_null\")\n",
    "                    RNE_[datedebut_autre].append(\"existence_null\")\n",
    "                    RNE_[datefin_autre].append(\"existence_null\")\n",
    "                    RNE_[dateeffetferm_autre].append(\"existence_null\")\n",
    "                    RNE_[dateeffettrans_autre].append(\"existence_null\")\n",
    "                \n",
    "        else:\n",
    "            \n",
    "               for j in range(10):\n",
    "                   \n",
    "                   ape_autre = autre_ape[j]\n",
    "                   statutFormalites_autre = autre_statutFormalites[j]\n",
    "                   role_autre = autre_role[j]\n",
    "                   adresse_autre = autre_adresse[j]\n",
    "                   datefin_autre = autre_datefin[j]\n",
    "                   dateeffetferm_autre = autre_dateeffetferm[j]\n",
    "                   datedebut_autre = autre_datedebut[j]\n",
    "                   dateeffettrans_autre = autre_dateeffettrans[j]\n",
    "                   \n",
    "                   \n",
    "                   RNE_[ape_autre].append(\"existence_null\")\n",
    "                   RNE_[statutFormalites_autre].append(\"existence_null\")\n",
    "                   RNE_[role_autre].append(\"existence_null\")\n",
    "                   RNE_[adresse_autre].append(\"existence_null\")\n",
    "                   RNE_[datedebut_autre].append(\"existence_null\")\n",
    "                   RNE_[datefin_autre].append(\"existence_null\")\n",
    "                   RNE_[dateeffetferm_autre].append(\"existence_null\")\n",
    "                   RNE_[dateeffettrans_autre].append(\"existence_null\")\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "        # --- Identité entreprise ---\n",
    "        identite = personneMorale.get(\"identite\", {})\n",
    "        entreprise = identite.get(\"entreprise\", {})\n",
    "        description = identite.get(\"description\", {})\n",
    "    \n",
    "        RNE_[\"denomination\"].append(entreprise.get(\"denomination\", \"non-disp\"))\n",
    "        RNE_[\"nicSiege\"].append(entreprise.get(\"nicSiege\", \"non-disp\"))\n",
    "        RNE_[\"codeAPE\"].append(entreprise.get(\"codeApe\", \"non-disp\"))\n",
    "        RNE_[\"dateImmat\"].append(entreprise.get(\"dateImmat\", \"non-disp\"))\n",
    "        RNE_[\"dateDebutAct\"].append(entreprise.get(\"dateDebutActiv\", \"non-disp\"))\n",
    "    \n",
    "        RNE_[\"objet\"].append(description.get(\"objet\", \"non-disp\"))\n",
    "        RNE_[\"capitalVariable\"].append(description.get(\"capitalVariable\", \"non-disp\"))\n",
    "        RNE_[\"montantCapital\"].append(description.get(\"montantCapital\", \"non-disp\"))\n",
    "        \n",
    "        # --- Informations sur les associés au pouvoir ---\n",
    "        compo = personneMorale.get(\"composition\")\n",
    "        \n",
    "        if compo is not None:\n",
    "            pouvoirs = compo.get(\"pouvoirs\")\n",
    "            \n",
    "          \n",
    "            i = -1\n",
    "            for i in range(min(len(pouvoirs),5)):\n",
    "                  \n",
    "                  role_associe = associe_role[i]\n",
    "                  nom_associe = associe_nom[i]\n",
    "                  prenom_associe = associe_prenom[i]\n",
    "                  id_associe = associe_id[i]\n",
    "                  naissance_associe = associe_naissance[i]\n",
    "                  \n",
    "                  if pouvoirs[i].get(\"typeDePersonne\") == \"INDIVIDU\":\n",
    "                      \n",
    "                      RNE_[role_associe].append(pouvoirs[i].get(\"roleEntreprise\",\"non-disp\"))\n",
    "                      \n",
    "                      RNE_[nom_associe].append(pouvoirs[i].get(\"individu\").get(\"descriptionPersonne\").get(\"nom\")\n",
    "                                              if pouvoirs[i].get(\"individu\") else \"non-disp\")\n",
    "                      \n",
    "                      prenoms_is = pouvoirs[i].get(\"individu\").get(\"descriptionPersonne\").get(\"prenoms\")\n",
    "    \n",
    "                      if isinstance(prenoms_is,list) and len(prenoms_is) > 0 :\n",
    "                          RNE_[prenom_associe].append(pouvoirs[i].get(\"individu\").get(\"descriptionPersonne\").get(\"prenoms\")[0]\n",
    "                                              if (pouvoirs[i].get(\"individu\")) else \"non-disp\")\n",
    "                      else:\n",
    "                          RNE_[prenom_associe].append(\"non-disp\")\n",
    "                      \n",
    "                      RNE_[naissance_associe].append(pouvoirs[i].get(\"individu\").get(\"descriptionPersonne\").get(\"dateDeNaissance\")\n",
    "                                              if pouvoirs[i].get(\"individu\") else \"non-disp\")\n",
    "                      \n",
    "                      RNE_[id_associe].append(pouvoirs[i].get(\"representantId\"))\n",
    "                      \n",
    "                  else:\n",
    "                      \n",
    "                      RNE_[role_associe].append(\"MORALE\")\n",
    "                      RNE_[nom_associe].append(\"MORALE\")\n",
    "                      RNE_[prenom_associe].append(\"MORALE\")\n",
    "                      RNE_[naissance_associe].append(\"MORALE\")\n",
    "                      RNE_[id_associe].append(\"MORALE\")\n",
    "            \n",
    "            if -1 <= i < 4:\n",
    "                for j in range(i+1,5):\n",
    "                      \n",
    "                      role_associe = associe_role[j]\n",
    "                      nom_associe = associe_nom[j]\n",
    "                      prenom_associe = associe_prenom[j]\n",
    "                      naissance_associe = associe_naissance[j]\n",
    "                      id_associe = associe_id[j]\n",
    "                      \n",
    "                      RNE_[role_associe].append(\"existence_null\")\n",
    "                      RNE_[nom_associe].append(\"existence_null\")\n",
    "                      RNE_[prenom_associe].append(\"existence_null\")\n",
    "                      RNE_[naissance_associe].append(\"existence_null\")\n",
    "                      RNE_[id_associe].append(\"existence_null\")\n",
    "                      \n",
    "        else:\n",
    "            for k in range(5):\n",
    "                        \n",
    "                  role_associe = associe_role[k]\n",
    "                  nom_associe = associe_nom[k]\n",
    "                  prenom_associe = associe_prenom[k]\n",
    "                  naissance_associe = associe_naissance[k]\n",
    "                  id_associe = associe_id[k]\n",
    "                  \n",
    "                  RNE_[role_associe].append(\"existence_null\")\n",
    "                  RNE_[nom_associe].append(\"existence_null\")\n",
    "                  RNE_[prenom_associe].append(\"existence_null\")\n",
    "                  RNE_[naissance_associe].append(\"existence_null\")\n",
    "                  RNE_[id_associe].append(\"existence_null\")\n",
    "            \n",
    "                    \n",
    "                    \n",
    "        # --- Est dans personne physique mais pas morale --- \n",
    "        for v in [\"nom\", \"prenoms\", \"genre\",\"age_physique\"]:\n",
    "            RNE_[v].append(\"non-disp\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # CAS 2 : PERSONNE PHYSIQUE\n",
    "    # ===================================================================\n",
    "    elif personnePhysique is not None:\n",
    "        RNE_[\"personneMorale\"].append(0)\n",
    "    \n",
    "        # --- Adresse ---\n",
    "        adresse = personnePhysique.get(\"adresseEntreprise\", {}).get(\"adresse\", {})\n",
    "        RNE_[\"code_postal\"].append(adresse.get(\"codePostal\", \"non-disp\"))\n",
    "        RNE_[\"voie\"].append(adresse.get(\"voie\", \"non-disp\"))\n",
    "        RNE_[\"codeInseeCommune\"].append(adresse.get(\"codeInseeCommune\", \"non-disp\"))\n",
    "        RNE_[\"numVoie\"].append(adresse.get(\"numVoie\", \"non-disp\"))\n",
    "        RNE_[\"typeVoie\"].append(adresse.get(\"typeVoie\", \"non-disp\"))\n",
    "    \n",
    "        # --- APE nicsiege dateimmat datedévutact formejuridique ---\n",
    "        firme_info = personnePhysique.get(\"identite\", {}).get(\"entreprise\", {})\n",
    "        RNE_[\"codeAPE\"].append(firme_info.get(\"codeApe\",\"non-disp\"))\n",
    "        RNE_[\"nicSiege\"].append(firme_info.get(\"nicSiege\",\"non-disp\"))\n",
    "        RNE_[\"dateImmat\"].append(firme_info.get(\"dateImmat\", \"non-disp\"))\n",
    "        RNE_[\"dateDebutAct\"].append(firme_info.get(\"dateDebutActiv\", \"non-disp\"))\n",
    "        \n",
    "        \n",
    "        # --- Information sur la cessation si cessation ---\n",
    "        cessation_info = personnePhysique.get(\"detailCessationEntreprise\", {})\n",
    "        RNE_[\"dateEffet\"].append(cessation_info.get(\"dateEffet\", \"non-disp\"))\n",
    "        RNE_[\"dateRadiation\"].append(cessation_info.get(\"dateRadiation\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDecesEntrepreneur\"].append(cessation_info.get(\"indicateurDecesEntrepreneur\", \"non-disp\"))\n",
    "        RNE_[\"dateCessationTotaleActivite\"].append(cessation_info.get(\"dateCessationTotaleActivite\", \"non-disp\"))\n",
    "        RNE_[\"dateClotureLiquidation\"].append(cessation_info.get(\"dateClotureLiquidation\", \"non-disp\"))\n",
    "        RNE_[\"dateDissolutionDisparition\"].append(cessation_info.get(\"dateDissolutionDisparition\", \"non-disp\"))\n",
    "        RNE_[\"indicateurCessationTemporaire\"].append(cessation_info.get(\"indicateurCessationTemporaire\", \"non-disp\"))\n",
    "        RNE_[\"indicateurPoursuiteActivite\"].append(cessation_info.get(\"indicateurPoursuiteActivite\", \"non-disp\"))\n",
    "        RNE_[\"indicateurMaintienImmatriculationRegistre\"].append(cessation_info.get(\"indicateurMaintienImmatriculationRegistre\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDissolution\"].append(cessation_info.get(\"indicateurDissolution\", \"non-disp\"))\n",
    "        RNE_[\"typeDissolution\"].append(cessation_info.get(\"typeDissolution\", \"non-disp\"))\n",
    "        RNE_[\"indicateurDisparitionPM\"].append(cessation_info.get(\"indicateurDisparitionPM\", \"non-disp\"))\n",
    "        RNE_[\"motifDisparition\"].append(cessation_info.get(\"motifDisparition\", \"non-disp\"))\n",
    "        RNE_[\"dateMiseEnSommeil\"].append(cessation_info.get(\"dateMiseEnSommeil\", \"non-disp\"))\n",
    "        \n",
    "        \n",
    "        # --- Information sur l'établissement principal si existence + historique (statutPourFormalitePrincipal) ---\n",
    "        principal = personnePhysique.get(\"etablissementPrincipal\")\n",
    "        RNE_[\"rolePourEntreprisePrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"rolePourEntreprise\",\"non-disp\") \n",
    "        if principal is not None else \"principal_false\")\n",
    "        \n",
    "        RNE_[\"statutPourFormalitePrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"statutPourFormalite\",\"non-disp\") \n",
    "        if principal is not None else \"principal_false\")\n",
    "    \n",
    "        RNE_[\"principalAPEPrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"codeAPE\",\"non-disp\") \n",
    "        if principal is not None else \"principal_false\")\n",
    "    \n",
    "        RNE_[\"principalDateTransPrincipal\"].append(principal.get(\"descriptionEtablissement\").get(\"dateEffetTransfert\",\"non-disp\") \n",
    "        if principal is not None else \"pincipal_false_transfert\")\n",
    "        \n",
    "        # --- Information sur les établissements secondaires si existence + historique ---\n",
    "        autres = personnePhysique.get(\"autresEtablissements\")\n",
    "        if autres is not None:\n",
    "            \n",
    "            RNE_[\"nb_autres\"].append(len(autres))\n",
    "            \n",
    "            i = -1\n",
    "            \n",
    "            for i in range(min(len(autres),10)):\n",
    "              \n",
    "                ape_autre = autre_ape[i]\n",
    "                statutFormalites_autre = autre_statutFormalites[i]\n",
    "                role_autre = autre_role[i]\n",
    "                adresse_autre = autre_adresse[i]\n",
    "                datefin_autre = autre_datefin[i]\n",
    "                dateeffetferm_autre = autre_dateeffetferm[i]\n",
    "                datedebut_autre = autre_datedebut[i]\n",
    "                dateeffettrans_autre = autre_dateeffettrans[i]\n",
    "                \n",
    "                RNE_[ape_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"codeApe\",\"non-disp\"))\n",
    "                RNE_[statutFormalites_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"statutPourFormalite\",\"non-disp\"))\n",
    "                RNE_[role_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"rolePourEntreprise\",\"non-disp\"))\n",
    "                RNE_[adresse_autre].append(autres[i].get(\"adresse\").get(\"codePostal\",\"non-disp\"))\n",
    "                RNE_[datedebut_autre].append(autres[i].get(\"activites\")[0].get(\"dateDebut\",\"non-disp\") if len(autres[i].get(\"activites\")) > 0 \n",
    "                                                    else \"non-disp\")\n",
    "                RNE_[datefin_autre].append(autres[i].get(\"activites\")[0].get(\"dateFin\",\"actif\") if len(autres[i].get(\"activites\")) > 0 \n",
    "                                                    else \"non-disp\")\n",
    "                RNE_[dateeffetferm_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"dateEffetFermeture\",\"non-disp\"))\n",
    "                RNE_[dateeffettrans_autre].append(autres[i].get(\"descriptionEtablissement\").get(\"dateEffetTransfert\",\"non-disp\"))\n",
    "            \n",
    "            if -1 <= i < 9:\n",
    "                \n",
    "                for j in range(i+1,10):\n",
    "                    \n",
    "                    ape_autre = autre_ape[j]\n",
    "                    statutFormalites_autre = autre_statutFormalites[j]\n",
    "                    role_autre = autre_role[j]\n",
    "                    adresse_autre = autre_adresse[j]\n",
    "                    datefin_autre = autre_datefin[j]\n",
    "                    dateeffetferm_autre = autre_dateeffetferm[j]\n",
    "                    datedebut_autre = autre_datedebut[j]\n",
    "                    dateeffettrans_autre = autre_dateeffettrans[j]\n",
    "                    \n",
    "                    \n",
    "                    RNE_[ape_autre].append(\"existence_null\")\n",
    "                    RNE_[statutFormalites_autre].append(\"existence_null\")\n",
    "                    RNE_[role_autre].append(\"existence_null\")\n",
    "                    RNE_[adresse_autre].append(\"existence_null\")\n",
    "                    RNE_[datedebut_autre].append(\"existence_null\")\n",
    "                    RNE_[datefin_autre].append(\"existence_null\")\n",
    "                    RNE_[dateeffetferm_autre].append(\"existence_null\")\n",
    "                    RNE_[dateeffettrans_autre].append(\"existence_null\")\n",
    "                    \n",
    "        else:\n",
    "            for j in range(10):\n",
    "                \n",
    "                ape_autre = autre_ape[j]\n",
    "                statutFormalites_autre = autre_statutFormalites[j]\n",
    "                role_autre = autre_role[j]\n",
    "                adresse_autre = autre_adresse[j]\n",
    "                datefin_autre = autre_datefin[j]\n",
    "                dateeffetferm_autre = autre_dateeffetferm[j]\n",
    "                datedebut_autre = autre_datedebut[j]\n",
    "                dateeffettrans_autre = autre_dateeffettrans[j]\n",
    "                \n",
    "                \n",
    "                RNE_[ape_autre].append(\"existence_null\")\n",
    "                RNE_[statutFormalites_autre].append(\"existence_null\")\n",
    "                RNE_[role_autre].append(\"existence_null\")\n",
    "                RNE_[adresse_autre].append(\"existence_null\")\n",
    "                RNE_[datedebut_autre].append(\"existence_null\")\n",
    "                RNE_[datefin_autre].append(\"existence_null\")\n",
    "                RNE_[dateeffetferm_autre].append(\"existence_null\")\n",
    "                RNE_[dateeffettrans_autre].append(\"existence_null\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # --- Identité de la personne physique ---\n",
    "        identite = personnePhysique.get(\"identite\", {}).get(\"entrepreneur\", {}).get(\"descriptionPersonne\", {})\n",
    "        RNE_[\"nom\"].append(identite.get(\"nom\", \"non-disp\"))\n",
    "        RNE_[\"prenoms\"].append(identite.get(\"prenoms\")[0] if isinstance(identite.get(\"prenoms\"),list) and len(identite.get(\"prenoms\"))>0 else 'non-disp')\n",
    "        RNE_[\"genre\"].append(identite.get(\"genre\", \"non-disp\"))\n",
    "        RNE_[\"age_physique\"].append(identite.get(\"dateDeNaissance\",\"non-disp\"))\n",
    "        \n",
    "        # --- objet ---\n",
    "        \n",
    "        \n",
    "        RNE_[\"objet\"].append(personnePhysique.get(\"etablissementPrincipal\").get(\"activites\")[0].get(\"descriptionDetaillee\") if \n",
    "        (personnePhysique.get(\"etablissementPrincipal\") is not None) and (isinstance(personnePhysique.get(\"etablissementPrincipal\").get(\"activites\"),list)) and (len(personnePhysique.get(\"etablissementPrincipal\").get(\"activites\")) >0) else \"non-disp\")\n",
    "        \n",
    "        # --- Est dans personne morale mais pas physique --- \n",
    "        RNE_[\"capitalVariable\"].append(\"non-disp\")\n",
    "        RNE_[\"montantCapital\"].append(\"non-disp\")\n",
    "        RNE_[\"denomination\"].append(\"non-disp\")\n",
    "        \n",
    "        for j in range(0,5):\n",
    "              \n",
    "              role_associe = associe_role[j]\n",
    "              nom_associe = associe_nom[j]\n",
    "              prenom_associe = associe_prenom[j]\n",
    "              naissance_associe = associe_naissance[j]\n",
    "              id_associe = associe_id[j]\n",
    "              \n",
    "              RNE_[role_associe].append(\"physique\")\n",
    "              RNE_[nom_associe].append(\"physique\")\n",
    "              RNE_[prenom_associe].append(\"physique\")\n",
    "              RNE_[naissance_associe].append(\"physique\")\n",
    "              RNE_[id_associe].append(\"physique\")\n",
    "    \n",
    "    \n",
    "    # --- Forme d’exercice , diffusion Insee et commerciale ---\n",
    "    RNE_[\"formeExerciceActivitePrincipale\"].append(content.get(\"formeExerciceActivitePrincipale\", \"non-disp\"))\n",
    "    RNE_[\"diffusionINSEE\"].append(content.get(\"diffusionINSEE\", \"non-disp\"))\n",
    "    RNE_[\"diffusionCommerciale\"].append(content.get(\"diffusionCommerciale\", \"non-disp\"))\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2bcd9",
   "metadata": {},
   "source": [
    "Nous partitionnons la récupération en plusieurs intervalles de temps, afin de ne pas saturer la mémoire \n",
    "lors de la mise en forme des data frame avec pandas, et d'autre part pour ne pas se retrouver avec des fichiers parquet trop gros, bien que ce format soit plus adapté et optimisé pour des grosses volumétries de données. L'exécution de cette cellule peut prendre du temps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_BUCKET = \"guillaume176\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [00:00<00:00, 3477024.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itération 1/14, préparation de RNE_1990_2000.parquet \n",
      "\n",
      "Data frame RNE_1990_2000.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_1980_1990.parquet \n",
      "\n",
      "itération 2/14, préparation de RNE_1990_2000.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [49:30<00:00,  4.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_1990_2000.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_1990_2000.parquet \n",
      "\n",
      "itération 3/14, préparation de RNE_2000_2005.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [43:51<00:00,  4.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2000_2005.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2000_2005.parquet \n",
      "\n",
      "itération 4/14, préparation de RNE_2005_2010.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [39:25<00:00,  5.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2005_2010.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2005_2010.parquet \n",
      "\n",
      "itération 5/14, préparation de RNE_2010_2015.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [39:45<00:00,  5.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2010_2015.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2010_2015.parquet \n",
      "\n",
      "itération 6/14, préparation de RNE_2015_2017.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [38:24<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2015_2017.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2015_2017.parquet \n",
      "\n",
      "itération 7/14, préparation de RNE_2017_2018.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:50<00:00,  5.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2017_2018.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2017_2018.parquet \n",
      "\n",
      "itération 8/14, préparation de RNE_2018_2019.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:39<00:00,  5.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2018_2019.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2018_2019.parquet \n",
      "\n",
      "itération 9/14, préparation de RNE_2019_2020.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:34<00:00,  5.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2019_2020.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2019_2020.parquet \n",
      "\n",
      "itération 10/14, préparation de RNE_2020_2021.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:53<00:00,  5.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2020_2021.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2020_2021.parquet \n",
      "\n",
      "itération 11/14, préparation de RNE_2021_2022.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:15<00:00,  5.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2021_2022.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2021_2022.parquet \n",
      "\n",
      "itération 12/14, préparation de RNE_2022_2023.parquet \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13098/13098 [37:37<00:00,  5.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame RNE_2022_2023.parquet prêt sur S3 \n",
      "\n",
      "guillaume176/diffusion/data_RNE/RNE_2022_2023.parquet \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dates_select = [1980,1990,2000,2005,2010,2015,2017,2018,2019,2020,2021,2022,2023,2024]\n",
    "\n",
    "for i in range(1,len(dates_select)):\n",
    "\n",
    "    df_name = f\"RNE_{dates_select[i-1]}_{dates_select[i]}.parquet\"\n",
    "\n",
    "    FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/diffusion/data_RNE/{df_name}\"\n",
    "\n",
    "    print(f\"itération {i}/{len(dates_select)-1}, préparation de {df_name} \\n\")\n",
    "\n",
    "    date_min = dates_select[i-1]\n",
    "    date_max = dates_select[i]\n",
    "    \n",
    "    RNE_ = prepare_RNE_Dict()\n",
    "    for firme_it in get_RNE_past([date_min,1,1], [date_max,1,1]):\n",
    "        get_RNE_DataFrame(firme_it)\n",
    "\n",
    "    data = pd.DataFrame(RNE_)\n",
    "    data = data.astype(str)\n",
    "\n",
    "    with fs.open(FILE_PATH_OUT_S3,\"wb\") as file_out:\n",
    "        data.to_parquet(file_out, index=False)\n",
    "\n",
    "    print(f\"Data frame {df_name} prêt sur S3 \\n\")\n",
    "    print(f\"{fs.ls(\"guillaume176/diffusion/data_RNE\")[-1]} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4ac86",
   "metadata": {},
   "source": [
    "### Voici une liste synthétique des variables obtenues : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f08d66",
   "metadata": {},
   "source": [
    "\n",
    "## Description\n",
    "153 Variables :\n",
    "## 1. Informations générales sur l’entreprise\n",
    "- `siren` : numéro SIREN  \n",
    "- `denomination` : nom de l’entreprise  \n",
    "- `formeJuridique` : forme juridique (SARL, SAS…)  \n",
    "- `date_creation` : date de création  \n",
    "- `dateImmat` : date d’immatriculation  \n",
    "- `dateCessationTotaleActivite` : date de cessation totale  \n",
    "- `dateRadiation` : date de radiation  \n",
    "- `dateClotureLiquidation` : date de clôture liquidation  \n",
    "- `dateDissolutionDisparition` : date dissolution/disparition  \n",
    "- `motifDisparition` : motif de disparition  \n",
    "- `capitalVariable` : indicateur capital variable  \n",
    "- `montantCapital` : montant du capital  \n",
    "- `objet` : objet social  \n",
    "- `codeAPE` : code APE principal  \n",
    "- `formeExerciceActivitePrincipale` : forme d’exercice de l’activité principale  \n",
    "- `personneMorale` : indicateur si entreprise est personne morale  \n",
    "- `nicSiege` : NIC du siège  \n",
    "- `etranger` : indicateur entreprise étrangère  \n",
    "- `micro` : indicateur micro-entreprise  \n",
    "- `agricole` : indicateur activité agricole  \n",
    "- `eirl` : indicateur EIRL  \n",
    "- `code_postal`, `codeInseeCommune` : localisation  \n",
    "- `voie`, `typeVoie`, `numVoie` : adresse du siège  \n",
    "- `cessation` : indicateur de cessation d’activité  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Activité et formalité principale\n",
    "- `dateDebutAct` : date début activité  \n",
    "- `rolePourEntreprisePrincipal` : rôle dans l’entreprise  \n",
    "- `statutPourFormalitePrincipal` : statut pour formalité principale  \n",
    "- `principalAPEPrincipal` : code APE principal  \n",
    "- `principalDateTransPrincipal` : date de transmission principale  \n",
    "- `indicateurDecesEntrepreneur` : indicateur décès entrepreneur  \n",
    "- `indicateurCessationTemporaire` : indicateur de cessation temporaire  \n",
    "- `indicateurPoursuiteActivite` : indicateur poursuite d’activité  \n",
    "- `indicateurMaintienImmatriculationRegistre` : indicateur maintien immatriculation  \n",
    "- `indicateurDissolution` : indicateur dissolution  \n",
    "- `indicateurDisparitionPM` : indicateur disparition personne morale  \n",
    "- `dateMiseEnSommeil` : date mise en sommeil  \n",
    "- `typeDissolution` : type de dissolution  \n",
    "- `nb_autres` : nombre d’autres établissements\n",
    "- `motifDisparition` : motif de la disparition de l'entreprise\n",
    "- `diffusionCommerciale` : autorisation diffusion commerciale\n",
    "- `diffusionINSEE` : autorisation diffusion Insee\n",
    "---\n",
    "\n",
    "## 3. Autres activités / formalités secondaires\n",
    "Variables répétitives pour `i` allant de 1 à 10 :  \n",
    "- `autre_i_ape` : code APE secondaire  \n",
    "- `autre_i_statutFormalites` : statut de la formalité secondaire  \n",
    "- `autre_i_role` : rôle dans l’activité secondaire  \n",
    "- `autre_i_adresse` : adresse de l’activité secondaire  \n",
    "- `autre_i_datefin` : date de fin de l’activité  \n",
    "- `autre_i_dateeffetferm` : date effet fermeture secondaire\n",
    "- `autre_i_datedebut` : date début de l’activité secondaire\n",
    "- `autre_i_dateeffettrans` : date effet transmission\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Associés (personnes morale)\n",
    "Variables répétitives pour `i` allant de 1 à 5 :  \n",
    "- `associe_i_id` : identifiant interne de l’associé  \n",
    "- `associe_i_role` : rôle dans l’entreprise de l'associé  \n",
    "- `associe_i_nom` : nom associé\n",
    "- `associe_i_prenom` : prénom associé \n",
    "- `associe_i_naissance` : date de naissance associé\n",
    "\n",
    "## 5. Informations personnes physiques\n",
    "- `nom` : nom de la personne physique\n",
    "- `prenom`: prénom de la personne physique\n",
    "- `age_physique` : age de la personne physique\n",
    "\n",
    "\n",
    "## Fichiers fournis sur le ssp cloud S3 guillaume176/diffusion/data_RNE: \n",
    "- `RNE_1980_1990.parquet`\n",
    "- `RNE_1990_2000.parquet`\n",
    "- `RNE_2000_2005.parquet`\n",
    "- `RNE_2005_2010.parquet`\n",
    "- `RNE_2010_2015.parquet`\n",
    "- `RNE_2015_2017.parquet`\n",
    "- `RNE_2017_2018.parquet`\n",
    "- `RNE_2018_2019.parquet`\n",
    "- `RNE_2019_2020.parquet`\n",
    "- `RNE_2020_2021.parquet`\n",
    "- `RNE_2021_2022.parquet`\n",
    "- `RNE_2022_2023.parquet`\n",
    "- `RNE_2023_2024.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec63aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"guillaume176/diffusion/data_RNE\"\n",
    "file_list = fs.ls(path_data)[1:]\n",
    "\n",
    "file_list = [\"https://minio.lab.sspcloud.fr/\" + f for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c19b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1980_1990.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1990_2000.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2000_2005.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2005_2010.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2010_2015.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2015_2017.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2017_2018.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2018_2019.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2019_2020.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2020_2021.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2021_2022.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2022_2023.parquet',\n",
       " 'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2023_2024.parquet']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Liens de téléchargement des données\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b15469",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae1973",
   "metadata": {},
   "source": [
    "## I.1.2 - Récupération des entreprises crées en IDF depuis 2010 jusqu'en 2024 pour les secteurs du commerce, de la restauration et de l'hôtellerie ; Récupération des expériences passés des entrepreneurs : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5008f85",
   "metadata": {},
   "source": [
    "Le but de cette partie est d'obtenir un data frame sur lequel nous travaillerons tout au long de ce projet. Nous décidons de récupérer l'ensemble des entreprises françaises crées entre 2010 et 2024, dont l'adresse principale est en Ile de France, pour les secteurs du commerce, de l'hôtellerie et la restauration. \n",
    "\n",
    "Notre choix s'explique par le fait que récupérer des entreprises crées à des dates trop lointaines pourraient fausser les résultats de la modélisation choisie, puisque par exemple, le tissu économique français des années 80 est drastiquement différent de celui d'aujourd'hui. \n",
    "De même, récupérer trop de secteurs différents pourrait entraîner une incapacité du modèle que l'on choisira à discriminer entre les entreprises radiées et non-radiées, qui sera notre variable cible à prédire.\n",
    "\n",
    "Le choix de l'Ile de France s'explique aussi pour les mêmes raisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1a36a",
   "metadata": {},
   "source": [
    "--------------------\n",
    "Nous donnons ici une suite de fonction permettant de récupérer ce data frame. Nous récupérons au passage des variables concernant l'expérience potentielle des associés et des personnes physiques, qui nécessitent un traitement assez lourd. Pour simplifier les choses, on considéra qu'une personne physique est l'associé 0.\n",
    "\n",
    "Voici la stratégie retenue pour n'obtenir qu'un seul data frame exploitable.\n",
    "\n",
    "- La fonction `get_RNE_Exp` permet de récupérer l'expérience des associés. Cette fonction est la raison principale pour laquelle nous incluons cette partie de notre travail dans la partie récupération des données, et non dans celle de l'analyse et feature engineering.\n",
    "En effet, nous voulons pour chaque entreprise d'IDF crées de 2010 à 2024 dans les secteurs visés, compter le nombre de fois où chaque associé à été enrôlé ou non dans une entreprise passé, c'est-à-dire crées avant la date de création concernant l'entreprise que nous regardons. Nous voulons aussi n'effectuer ce comptage que si l'associé à eu un rôle pertinent dans l'entreprise, le rendant le plus susceptible d'être à l'origine de la création bien que cela ne soit pas garanti. Enfin, nous voulons également compter le nombre d'entreprise radiée parmi les entreprises dans lesquelles l'associé en question à été enrôlé. Nous pensons en effet que ces variables permettront d'enrichir en information notre base de données, donnant plus de chance à un modèle de machine learning d'aboutir à des métriques satisfaisantes.\n",
    "Pour effectuer cela, nous voulons travailler avec deux data frames : l'un dit de \"travaille\", étant celui sur lequel nous nous concentrons (idf_10_24, appelé simplement df_p dans la fonction), l'autre dit \"historique\" (total_p), comprenant l'ensemble des entreprises crées partout en France, pour les \"grands\" secteurs du commerce, artisanat et artisanat réglementé, depuis 1980 jusqu'en 2024. Pour chaque entreprise dans idf_10_24, nous regardons si le combo nom + prénom + date de naissance pour un associé donné correspond à une entreprise crées dans le passé. Si oui, nous sélectionnons seulement les entreprises dans lesquels l'associé à eu un rôle important. Nous récupérons au passage le nombre d'entreprises passées radiées. \n",
    "Comme cette tâche nécessite de travailler avec un data frame de plus de 8 000 000 de lignes (total), pandas n'est pas adapté ici. Nous utilisons alors DuckDB permettant de faire des requêtes SQL simple et rapide. \n",
    "`On récupère ainsi les variables total_expi (expérience total de l'associé i), total_radi (nombre d'entreprises passés radiées liées à l'associé i) et ape_truei (nombre d'entreprises passés ayant un lien avec le secteur d'activité de l'entreprise actuelle liée à l'associé i).`\n",
    "\n",
    "\n",
    "Remarque : l'id (nom + prénom + date de naissance) est ici utilisé par défaut puisque les variables \"associe_i_id\" ne trouvent pas de correspondance dans le passé. Elles sont utiles simplement à l'identification interne d'un associé dans une entreprise donné.\n",
    "D'autre part, il se peut que deux personnes différentes partagent cet id, même si cela est rare. Ceci sera un point d'amélioration à considérer.\n",
    "\n",
    "- La fonction `get_RNE_MeanAge` permet de récupérer l'âge moyen des associées ainsi que le nombre d'associé.\n",
    "\n",
    "\n",
    "- La fonction `get_RNE_Final` permet de récupérer les données depuis le cloud ssp cloud S3 puis les préparer pour la fonction `get_RNE_Exp` ainsi pouvoir récupérer l'expérience de chaque associé. Elle récupère ensuite l'âge moyen des associés et le nombre d'associé grâce à la fonction `get_RNE_MeanAge`. Elle renvoie un data frame pandas. Cette fonction se veux flexible pour que les lecteurs de ce projet puissent récupérer d'autres années, départements, activités...\n",
    "\n",
    "- Finalement, nous exportons au format parquet le data frame obtenu sur le cloud, qui servira à la deuxième partie de la récupération de données.\n",
    "Voire plus loin pour le lien de téléchargement de ce data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a41206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_RNE_Exp(numero_associe : int, df_p : pd.DataFrame, total_p : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction qui permet de récupérer l'expérience d'un associée donné dont le numéro est compris en 1 et 5 ou bien celle\n",
    "    d'une personne physique (0).\n",
    "\n",
    "    \n",
    "    inputs : \n",
    "            - numero_associe : int compris en entre 0 et 5 (0 == personne physique)\n",
    "            - df_p : le dataframe RNE pour lequel on veut obtenir l'expérience des associés/personnes physiques\n",
    "            - total_p : le dataframe RNE complet servant d'historique\n",
    "\n",
    "    outputs :\n",
    "            - res : dataframe avec 4 colonnes : siren, total_expi, total_radi, ape_truei, dont siren corresponds aux siren de \n",
    "                    df.\n",
    "    \n",
    "    total_exp0, total_rad0 et ape_true0 concernent les personnes physiques\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if numero_associe > 0:\n",
    "        ass1_nom = f\"associe_{numero_associe}_nom\"\n",
    "        ass1_prenom = f\"associe_{numero_associe}_prenom\"\n",
    "        ass1_naissance = f\"associe_{numero_associe}_naissance\"\n",
    "    else:\n",
    "        ass1_nom = \"nom\"\n",
    "        ass1_prenom = \"prenoms\"\n",
    "        ass1_naissance = \"age_physique\"\n",
    "\n",
    "    df = df_p[[\"siren\",\"date_creation\",ass1_nom,ass1_prenom,ass1_naissance,\"associe_1_role\",\"codeAPE\"]].copy()\n",
    "\n",
    "    total = (total_p[[\"siren\",\"date_creation\",\n",
    "    \"associe_1_nom\",\"associe_1_prenom\",\"associe_1_naissance\",\"associe_1_role\",\n",
    "    \"associe_2_nom\",\"associe_2_prenom\",\"associe_2_naissance\",\"associe_2_role\",\n",
    "    \"associe_3_nom\",\"associe_3_prenom\",\"associe_3_naissance\",\"associe_3_role\",\n",
    "    \"associe_4_nom\",\"associe_4_prenom\",\"associe_4_naissance\",\"associe_4_role\",\n",
    "    \"associe_5_nom\",\"associe_5_prenom\",\"associe_5_naissance\",\"associe_5_role\",\n",
    "    \"nom\",\"prenoms\",\"age_physique\",\"dateRadiation\",\"codeAPE\"]]).copy()\n",
    "\n",
    "    df[ass1_nom] = df[ass1_nom].str.lower()\n",
    "    df[ass1_prenom] = df[ass1_prenom].str.lower()\n",
    "    df[ass1_naissance] = df[ass1_naissance].str.lower()\n",
    "\n",
    "\n",
    "    associe_nom = [f\"associe_{i}_nom\" for i in range(1,6)]\n",
    "    associe_prenom = [f\"associe_{i}_prenom\" for i in range(1,6)]\n",
    "    associe_naissance = [f\"associe_{i}_naissance\" for i in range(1,6)]\n",
    "    for i in range(len(associe_nom)):\n",
    "        total[associe_nom[i]] = total[associe_nom[i]].str.lower()\n",
    "        total[associe_prenom[i]] = total[associe_prenom[i]].str.lower()\n",
    "        total[associe_naissance[i]] = total[associe_naissance[i]].str.lower()\n",
    "\n",
    "    total[\"nom\"] = total[\"nom\"].str.lower()\n",
    "    total[\"prenoms\"] = total[\"prenoms\"].str.lower()\n",
    "    total[\"age_physique\"] = total[\"age_physique\"].str.lower()\n",
    "\n",
    "    df[\"siren\"] = df[\"siren\"].astype(int)\n",
    "    total[\"siren\"] = total[\"siren\"].astype(int)\n",
    "\n",
    "    total['dateRadiation'] = pd.to_datetime(total['dateRadiation'], errors='coerce')\n",
    "    \n",
    "\n",
    "    #Connexion DuckDB\n",
    "    con = duckdb.connect()\n",
    "\n",
    "    #Enregistrement des DataFrames pandas dans DuckDB\n",
    "    con.register(\"df\", df)        \n",
    "    con.register(\"total\", total)\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "    CREATE OR REPLACE VIEW total_long AS\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        associe_1_nom AS sname,\n",
    "        associe_1_prenom AS fname,\n",
    "        associe_1_naissance AS birth,\n",
    "        associe_1_role AS role\n",
    "    FROM total\n",
    "    WHERE associe_1_nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_1_prenom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_1_naissance NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_1_role IN ('28','29','41','53','73','74','75','101','65','66')\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        associe_2_nom,\n",
    "        associe_2_prenom,\n",
    "        associe_2_naissance,\n",
    "        associe_2_role\n",
    "    FROM total\n",
    "    WHERE associe_2_nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_2_prenom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_2_naissance NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_2_role IN ('28','29','41','53','73','74','75','101','65','66')\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        associe_3_nom,\n",
    "        associe_3_prenom,\n",
    "        associe_3_naissance,\n",
    "        associe_3_role\n",
    "    FROM total\n",
    "    WHERE associe_3_nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_3_prenom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_3_naissance NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_3_role IN ('28','29','41','53','73','74','75','101','65','66')\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        associe_4_nom,\n",
    "        associe_4_prenom,\n",
    "        associe_4_naissance,\n",
    "        associe_4_role\n",
    "    FROM total\n",
    "    WHERE associe_4_nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_4_prenom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_4_naissance NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_4_role IN ('28','29','41','53','73','74','75','101','65','66')\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        associe_5_nom,\n",
    "        associe_5_prenom,\n",
    "        associe_5_naissance,\n",
    "        associe_5_role\n",
    "    FROM total\n",
    "    WHERE associe_5_nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_5_prenom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_5_naissance NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND associe_5_role IN ('28','29','41','53','73','74','75','101','65','66')\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT siren, date_creation,dateRadiation,codeAPE,\n",
    "        nom,\n",
    "        prenoms,\n",
    "        age_physique,\n",
    "        associe_5_role\n",
    "    FROM total\n",
    "    WHERE nom NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND prenoms NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique')\n",
    "    AND age_physique NOT IN ('existence_null', 'non-disp', 'morale', 'none', 'physique');\n",
    "    \"\"\")\n",
    "\n",
    "    if numero_associe > 0:\n",
    "        #Requête principale pour l'historique d'un associé\n",
    "        res = con.execute(f\"\"\"\n",
    "        SELECT\n",
    "            df.siren,\n",
    "\n",
    "\n",
    "            COUNT(DISTINCT t.siren) AS total_exp{numero_associe},\n",
    "\n",
    "\n",
    "            COUNT(DISTINCT CASE\n",
    "                WHEN t.dateRadiation IS NOT NULL THEN t.siren\n",
    "            END) AS total_rad{numero_associe},\n",
    "\n",
    "            COUNT(DISTINCT CASE\n",
    "                WHEN SUBSTR(t.codeAPE, 1, 1) = SUBSTR(df.codeAPE, 1, 1) THEN t.siren\n",
    "            END) AS ape_true{numero_associe}\n",
    "\n",
    "        FROM df\n",
    "\n",
    "        LEFT JOIN total_long t\n",
    "        ON df.associe_{numero_associe}_nom = t.sname\n",
    "        AND df.associe_{numero_associe}_prenom = t.fname\n",
    "        AND df.associe_{numero_associe}_naissance = t.birth\n",
    "        AND t.date_creation < df.date_creation\n",
    "\n",
    "        GROUP BY df.siren\n",
    "        ORDER BY df.siren\n",
    "        \"\"\").df()\n",
    "\n",
    "\n",
    "    else:\n",
    "        #Requête principale pour  l'historique d'une personne physique\n",
    "        res = con.execute(f\"\"\"\n",
    "        SELECT\n",
    "            df.siren,\n",
    "\n",
    "\n",
    "            COUNT(DISTINCT t.siren) AS total_exp{numero_associe},\n",
    "\n",
    "\n",
    "            COUNT(DISTINCT CASE\n",
    "                WHEN t.dateRadiation IS NOT NULL THEN t.siren\n",
    "            END) AS total_rad{numero_associe},\n",
    "\n",
    "            COUNT(DISTINCT CASE\n",
    "                WHEN SUBSTR(t.codeAPE, 1, 1) = SUBSTR(df.codeAPE, 1, 1) THEN t.siren\n",
    "            END) AS ape_true{numero_associe}\n",
    "\n",
    "        FROM df\n",
    "\n",
    "        LEFT JOIN total_long t\n",
    "        ON df.nom = t.sname\n",
    "        AND df.prenoms = t.fname\n",
    "        AND df.age_physique = t.birth\n",
    "        AND t.date_creation < df.date_creation\n",
    "\n",
    "        GROUP BY df.siren\n",
    "        ORDER BY df.siren\n",
    "        \"\"\").df()\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abf4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNE_MeanAge(df : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction permettant de récupérer l'âge moyen des associés ainsi que le nombre d'associé pour chaque entreprise données.\n",
    "\n",
    "    inputs : \n",
    "            - df : data frame RNE\n",
    "    \n",
    "    ouputs : \n",
    "            - df : data frame enrichi de l'âge moyen des associés ainsi que le nombre d'associé.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Récupération du nombre d'associés\n",
    "    df[\"is1\"] = (~df[\"associe_1_nom\"].isin([\"non-disp\",\"MORALE\",\"None\",\"non-disp\",\"physique\",\"existence_null\",\"morale\",\"none\"])).astype(int)\n",
    "    df[\"is2\"] = (~df[\"associe_2_nom\"].isin([\"non-disp\",\"MORALE\",\"None\",\"non-disp\",\"physique\",\"existence_null\",\"morale\",\"none\"])).astype(int)\n",
    "    df[\"is3\"] = (~df[\"associe_3_nom\"].isin([\"non-disp\",\"MORALE\",\"None\",\"non-disp\",\"physique\",\"existence_null\",\"morale\",\"none\"])).astype(int)\n",
    "    df[\"is4\"] = (~df[\"associe_4_nom\"].isin([\"non-disp\",\"MORALE\",\"None\",\"non-disp\",\"physique\",\"existence_null\",\"morale\",\"none\"])).astype(int)\n",
    "    df[\"is5\"] = (~df[\"associe_5_nom\"].isin([\"non-disp\",\"MORALE\",\"None\",\"non-disp\",\"physique\",\"existence_null\",\"morale\",\"none\"])).astype(int)\n",
    "    df[\"personneMorale\"] = df[\"personneMorale\"].astype(int)\n",
    "\n",
    "    df[\"nb_associe\"] = df[\"is1\"] + df[\"is2\"]  + df[\"is3\"] + df[\"is4\"] + df[\"is5\"] + (1-df[\"personneMorale\"])\n",
    "    \n",
    "    #Récupération de l'âge moyen des associés à la création d'entreprises\n",
    "    df[\"associe_1_naissance\"] = (df[\"associe_1_naissance\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"associe_1_naissance\"] = pd.to_datetime(df[\"associe_1_naissance\"])\n",
    "\n",
    "    df[\"associe_2_naissance\"] = (df[\"associe_2_naissance\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"associe_2_naissance\"] = pd.to_datetime(df[\"associe_2_naissance\"])\n",
    "\n",
    "    \"\"\"\n",
    "    #Corrige un bug natif\n",
    "    i_error = df.loc[df[\"associe_3_naissance\"] == \"0997-08\"][\"associe_3_naissance\"].index\n",
    "    df[i_error, \"associe_3_naissance\"] = \"1997-08\"\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"associe_3_naissance\"] = (df[\"associe_3_naissance\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"associe_3_naissance\"] = pd.to_datetime(df[\"associe_3_naissance\"],errors='coerce')\n",
    "\n",
    "\n",
    "    df[\"associe_4_naissance\"] = (df[\"associe_4_naissance\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"associe_4_naissance\"] = pd.to_datetime(df[\"associe_4_naissance\"])\n",
    "\n",
    "    df[\"associe_5_naissance\"] = (df[\"associe_5_naissance\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"associe_5_naissance\"] = pd.to_datetime(df[\"associe_5_naissance\"])\n",
    "\n",
    "    df[\"age_physique\"] = (df[\"age_physique\"]\n",
    "    .apply(lambda x : x if x not in [\"MORALE\",\"physique\",\"existence_null\",\"None\",\"non-disp\"] else pd.NaT))\n",
    "    df[\"age_physique\"] = pd.to_datetime(df[\"age_physique\"])\n",
    " \n",
    "    \n",
    "    df[\"age0\"] = (df[\"date_creation\"] - df[\"age_physique\"])\n",
    "    df[\"age1\"] = (df[\"date_creation\"] - df[\"associe_1_naissance\"])\n",
    "    df[\"age2\"] = (df[\"date_creation\"] - df[\"associe_2_naissance\"])\n",
    "    df[\"age3\"] = (df[\"date_creation\"] - df[\"associe_3_naissance\"])\n",
    "    df[\"age4\"] = (df[\"date_creation\"] - df[\"associe_4_naissance\"])\n",
    "    df[\"age5\"] = (df[\"date_creation\"] - df[\"associe_5_naissance\"])\n",
    "\n",
    "   \n",
    "    df[\"age0\"] = df[\"age0\"].dt.total_seconds() / (86400 * 365.25)\n",
    "    df[\"age1\"] = df[\"age1\"].dt.total_seconds() / (86400 * 365.25)\n",
    "    df[\"age2\"] = df[\"age2\"].dt.total_seconds() / (86400 * 365.25)\n",
    "    df[\"age3\"] = df[\"age3\"].dt.total_seconds() / (86400 * 365.25)\n",
    "    df[\"age4\"] = df[\"age4\"].dt.total_seconds() / (86400 * 365.25)\n",
    "    df[\"age5\"] = df[\"age5\"].dt.total_seconds() / (86400 * 365.25)\n",
    "\n",
    "\n",
    "    df[\"mean_age\"] = (\n",
    "        df[[\"age0\",\"age1\", \"age2\", \"age3\", \"age4\", \"age5\"]]\n",
    "        .sum(axis=1, skipna=True)\n",
    "        / (df[\"nb_associe\"])\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3028cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNE_Final(dep : list, activites : list, date_min : list)-> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction permettant de récupérer les données du RNE sur le cloud ssp cloud S3, de récupérer les expériences passés des \n",
    "    associés, puis l'âge moyen des associés, ainsi que leur nombre, cela pour une liste de département et d'activités données,\n",
    "    ainsi qu'une date minimale de création.\n",
    "\n",
    "    inputs :\n",
    "            - dep : liste de département de type [\"78\",\"01\",...]\n",
    "            - activites : liste d'activités par \"bribes\" de code APE de type [\"45\",\"5610B\",...]\n",
    "            - date_min : date minimale de création de type [2021,1,1] == [y,month,day]\n",
    "    \n",
    "    outputs : \n",
    "            - df_return : data frame RNE\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ##################################################################################################\n",
    "    #    ETAPE 1 : Récupération des données selon dep, acitivtes et date_min + l'historique total    #\n",
    "    ##################################################################################################\n",
    "\n",
    "\n",
    "    #Récupération des données depuis le cloud ssp cloud S3\n",
    "    dates_select = [1980,1990,2000,2005,2010,2015,2017,2018,2019,2020,2021,2022,2023,2024]\n",
    "\n",
    "    dfs_rne = dict()\n",
    "    df_names = [(f\"df_{dates_select[i-1]}_{dates_select[i]}\",i) for i in range(1,len(dates_select))]\n",
    "\n",
    "    url_dataRNE = ['https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1980_1990.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1990_2000.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2000_2005.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2005_2010.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2010_2015.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2015_2017.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2017_2018.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2018_2019.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2019_2020.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2020_2021.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2021_2022.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2022_2023.parquet',\n",
    "    'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2023_2024.parquet']\n",
    "\n",
    "    for names,i in tqdm(df_names):\n",
    "        print(f\"Récupération depuis le cloud {i}/13\")\n",
    "        url = url_dataRNE[i-1]\n",
    "        df = pd.read_parquet(url)\n",
    "        dfs_rne[names] = df\n",
    "    #------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #Récupération des colonnes et création d'un nouveau data frame vide\n",
    "    columns_rne = list(dfs_rne[df_names[0][0]].columns)\n",
    "    idf_10_24 = pd.DataFrame(columns=columns_rne)\n",
    "\n",
    "    #Filtrage par activites et département\n",
    "    for names in tqdm(df_names):\n",
    "        print(\"Filtrage par département et activités\")\n",
    "        data = dfs_rne[names[0]]\n",
    "        data = data[data[\"codeAPE\"].str.startswith(tuple(activites)) & data[\"code_postal\"].str.startswith(tuple(dep))]\n",
    "        idf_10_24 = pd.concat([idf_10_24,data])\n",
    "        \n",
    "    #Filtrage pour les dates de création après 2010-01-01 (inlcus)\n",
    "    idf_10_24[\"date_creation\"] = pd.to_datetime(idf_10_24[\"date_creation\"])\n",
    "\n",
    "    print(f\"Récupération depuis {date_min[0]}-{date_min[1]}-{date_min[2]}\")\n",
    "    idf_10_24 = idf_10_24[idf_10_24[\"date_creation\"] >= datetime.datetime(date_min[0],date_min[1],date_min[2])]\n",
    "\n",
    "    idf_10_24[\"dateRadiation\"] = idf_10_24[\"dateRadiation\"].apply(lambda x : \n",
    "        x if x not in [\"non-disp\",\"None\"] else pd.NaT)\n",
    "\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #Récupération des colonnes et création d'un nouveau data frame vide\n",
    "    columns_rne = list(dfs_rne[df_names[0][0]].columns)\n",
    "    total = pd.DataFrame(columns=columns_rne)\n",
    "\n",
    "    #Récupération complète dans un data frame\n",
    "    print(\"Récupération de l'historique total\")\n",
    "    for names in tqdm(df_names):\n",
    "        data = dfs_rne[names[0]]\n",
    "        total = pd.concat([total,data])\n",
    "    \n",
    "\n",
    "    total[\"date_creation\"] = pd.to_datetime(total[\"date_creation\"])\n",
    "    total[\"dateRadiation\"] = total[\"dateRadiation\"].apply(lambda x : \n",
    "        x if x not in [\"non-disp\",\"None\"] else pd.NaT)\n",
    "\n",
    "    #########################################################################################################\n",
    "    #   ETAPE 2 : Récupération de l'expérience des associés/personnes physiques + age moyen à la création   #\n",
    "    #########################################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "    #Récupération de l'expérience des associés/personnes physiques\n",
    "    associe_list = [0,1,2,3,4,5]\n",
    "\n",
    "    idf_10_24[\"siren\"] = idf_10_24[\"siren\"].astype(int)\n",
    "\n",
    "    df_return = idf_10_24.copy()\n",
    "\n",
    "    for i in associe_list:\n",
    "        \n",
    "        print(f\"Récupération expérience associé {i}\")\n",
    "        res = get_RNE_Exp(numero_associe=i, df_p=idf_10_24, total_p=total)\n",
    "        res[\"siren\"] = res[\"siren\"].astype(int)\n",
    "        df_return = df_return.merge(res, on=\"siren\", how=\"left\")\n",
    "        \n",
    "    #Récupération de l'âge moyen à la création\n",
    "\n",
    "    print(\"Récupération de l'âge moyen\")\n",
    "    df_return = get_RNE_MeanAge(df_return)\n",
    "    \n",
    "\n",
    "    return df_return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fbb55",
   "metadata": {},
   "source": [
    "Les cellules suivantes permettent de récupérer les données et de les exporter vers le cloud ssp cloud S3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "220818eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:02<00:35,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 2/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:08<00:50,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 3/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:13<00:47,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 4/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:21<00:55,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 5/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:31<00:59,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 6/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:36<00:46,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 7/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [00:40<00:33,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 8/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [00:43<00:24,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 9/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [00:47<00:18,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 10/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:51<00:13,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 11/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:56<00:09,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 12/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [01:01<00:04,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 13/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:04<00:00,  4.92s/it]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:00<00:03,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:00<00:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:01<00:04,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:02<00:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:03<00:06,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:04<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [00:05<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [00:05<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [00:06<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:07<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:08<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [00:09<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage par département et activités\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis 2010-1-1\n",
      "Récupération de l'historique total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [02:06<00:00,  9.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération expérience associé 0\n",
      "Récupération expérience associé 1\n",
      "Récupération expérience associé 2\n",
      "Récupération expérience associé 3\n",
      "Récupération expérience associé 4\n",
      "Récupération expérience associé 5\n",
      "Récupération de l'âge moyen\n"
     ]
    }
   ],
   "source": [
    "#Listes des activités retenues par bribes d'APE (voire nomenclature NAF)\n",
    "activites_annotees = [\n",
    "    (\"4511Z\", \"Commerce de voitures et véhicules légers\"),\n",
    "    (\"4519Z\", \"Commerce d'autres véhicules automobiles\"),\n",
    "    (\"45\",    \"Entretien et réparation véhicules automobiles\"),\n",
    "    (\"454\",   \"Commerce et réparation de motocyclettes\"),\n",
    "    (\"461\",   \"Intermédiaires du commerce de gros\"),\n",
    "    (\"462\",   \"Commerce de gros produits agricoles et animaux vivants\"),\n",
    "    (\"463\",   \"Commerce de gros aliments, boissons et tabac\"),\n",
    "    (\"466\",   \"Commerce de gros autres équipements industriels\"),\n",
    "    (\"467\",   \"Autres commerces de gros spécialisés\"),\n",
    "    (\"471\",   \"Commerce de détail en magasin non spécialisé\"),\n",
    "    (\"472\",   \"Commerce de détail alimentaire en magasin spécialisé\"),\n",
    "    (\"473\",   \"Commerce de détail de carburants en magasin spécialisé\"),\n",
    "    (\"478\",   \"Commerce de détail sur éventaires et marchés\"),\n",
    "    (\"551\",   \"Hôtels et hébergement similaire\"),\n",
    "    (\"552\",   \"Hébergement touristique et autre hébergement courte durée\"),\n",
    "    (\"5610A\", \"Restauration traditionnelle\"),\n",
    "    (\"5610B\", \"Cafétérias et autres libres-services\"),\n",
    "    (\"5610C\", \"Restauration rapide\"),\n",
    "    (\"563\",    \"Débits de boissons\")\n",
    "]\n",
    "\n",
    "activites = [activites_annotees[i][0] for i in range(len(activites_annotees))]\n",
    "\n",
    "#Départements d'IDF\n",
    "dep = [\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\"]\n",
    "\n",
    "#Date minimale \n",
    "date_min = [2010,1,1]\n",
    "\n",
    "data = get_RNE_Final(dep=dep, activites=activites,date_min=date_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98d0d0",
   "metadata": {},
   "source": [
    "Exemple des nouvelles colonnes obtenues :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "687b19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>age_physique</th>\n",
       "      <th>associe_1_naissance</th>\n",
       "      <th>siren</th>\n",
       "      <th>age0</th>\n",
       "      <th>age1</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>nb_associe</th>\n",
       "      <th>total_exp1</th>\n",
       "      <th>total_rad1</th>\n",
       "      <th>ape_true1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARAFIAN</td>\n",
       "      <td>1950-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>300553369</td>\n",
       "      <td>61.456537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.456537</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1939-10-01</td>\n",
       "      <td>301051827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.397673</td>\n",
       "      <td>71.397673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1973-12-01</td>\n",
       "      <td>302315510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.950034</td>\n",
       "      <td>40.950034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>302452297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.753593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1964-06-01</td>\n",
       "      <td>303159875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.301848</td>\n",
       "      <td>44.551677</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1957-03-01</td>\n",
       "      <td>303968812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.240246</td>\n",
       "      <td>47.571983</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>304514698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.097878</td>\n",
       "      <td>41.097878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1952-09-01</td>\n",
       "      <td>305034019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.091718</td>\n",
       "      <td>58.091718</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1961-07-01</td>\n",
       "      <td>305147860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.117043</td>\n",
       "      <td>44.894365</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>non-disp</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1961-06-01</td>\n",
       "      <td>305933681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.133470</td>\n",
       "      <td>49.133470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nom age_physique associe_1_naissance      siren       age0       age1  \\\n",
       "0  SARAFIAN   1950-06-01                 NaT  300553369  61.456537        NaN   \n",
       "1  non-disp          NaT          1939-10-01  301051827        NaN  71.397673   \n",
       "2  non-disp          NaT          1973-12-01  302315510        NaN  40.950034   \n",
       "3  non-disp          NaT                 NaT  302452297        NaN        NaN   \n",
       "4  non-disp          NaT          1964-06-01  303159875        NaN  47.301848   \n",
       "5  non-disp          NaT          1957-03-01  303968812        NaN  57.240246   \n",
       "6  non-disp          NaT          1972-04-01  304514698        NaN  41.097878   \n",
       "7  non-disp          NaT          1952-09-01  305034019        NaN  58.091718   \n",
       "8  non-disp          NaT          1961-07-01  305147860        NaN  49.117043   \n",
       "9  non-disp          NaT          1961-06-01  305933681        NaN  49.133470   \n",
       "\n",
       "    mean_age  nb_associe  total_exp1  total_rad1  ape_true1  \n",
       "0  61.456537           1           0           0          0  \n",
       "1  71.397673           1           0           0          0  \n",
       "2  40.950034           1           0           0          0  \n",
       "3  39.753593           1           0           0          0  \n",
       "4  44.551677           2           2           0          0  \n",
       "5  47.571983           3           0           0          0  \n",
       "6  41.097878           1           0           0          0  \n",
       "7  58.091718           1           6           0          0  \n",
       "8  44.894365           3           1           0          0  \n",
       "9  49.133470           1           1           0          0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"nom\",\"age_physique\",\"associe_1_naissance\",\"siren\",\"age0\",\"age1\",\"mean_age\",\"nb_associe\",\"total_exp1\",\"total_rad1\",\"ape_true1\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e285239",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_BUCKET = \"guillaume176\"\n",
    "\n",
    "FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/diffusion/data_final/idf_10_24.parquet\"\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3,\"wb\") as file_out:\n",
    "    data.to_parquet(file_out, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5a6f2",
   "metadata": {},
   "source": [
    "Lien pour le téléchargement pour `idf_10_24`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dc6f525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_final/idf_10_24.parquet\n"
     ]
    }
   ],
   "source": [
    "path_data = \"guillaume176/diffusion/data_final\"\n",
    "file_list = fs.ls(path_data)[1:]\n",
    "file_list = [\"https://minio.lab.sspcloud.fr/\" + f for f in file_list]\n",
    "print(file_list[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
