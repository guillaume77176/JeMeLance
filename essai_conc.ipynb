{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383dc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:03<00:40,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération depuis le cloud 2/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:05<01:02,  5.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRécupération depuis le cloud \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/13\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m     url = url_dataRNE[i-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     dfs_rne[names] = df\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m#------------------------------------------------------------------------------------------------#\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m#Récupération des colonnes et création d'un nouveau data frame vide\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/io/parquet.py:265\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    259\u001b[39m     path,\n\u001b[32m    260\u001b[39m     filesystem,\n\u001b[32m    261\u001b[39m     storage_options=storage_options,\n\u001b[32m    262\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    263\u001b[39m )\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[32m    274\u001b[39m         filterwarnings(\n\u001b[32m    275\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmake_block is deprecated\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    277\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    278\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pyarrow/parquet/core.py:1899\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[39m\n\u001b[32m   1885\u001b[39m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[32m   1886\u001b[39m     dataset = ParquetFile(\n\u001b[32m   1887\u001b[39m         source, read_dictionary=read_dictionary,\n\u001b[32m   1888\u001b[39m         binary_type=binary_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1896\u001b[39m         page_checksum_verification=page_checksum_verification,\n\u001b[32m   1897\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1899\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1900\u001b[39m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pyarrow/parquet/core.py:1538\u001b[39m, in \u001b[36mParquetDataset.read\u001b[39m\u001b[34m(self, columns, use_threads, use_pandas_metadata)\u001b[39m\n\u001b[32m   1530\u001b[39m         index_columns = [\n\u001b[32m   1531\u001b[39m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[32m   1532\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   1533\u001b[39m         ]\n\u001b[32m   1534\u001b[39m         columns = (\n\u001b[32m   1535\u001b[39m             \u001b[38;5;28mlist\u001b[39m(columns) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) - \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[32m   1544\u001b[39m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Listes des activités retenues par bribes d'APE (voire nomenclature NAF)\n",
    "activites_annotees = [\n",
    "(\"4511Z\", \"Commerce de voitures et véhicules légers\"),\n",
    "(\"4519Z\", \"Commerce d'autres véhicules automobiles\"),\n",
    "(\"45\",    \"Entretien et réparation véhicules automobiles\"),\n",
    "(\"454\",   \"Commerce et réparation de motocyclettes\"),\n",
    "(\"461\",   \"Intermédiaires du commerce de gros\"),\n",
    "(\"462\",   \"Commerce de gros produits agricoles et animaux vivants\"),\n",
    "(\"463\",   \"Commerce de gros aliments, boissons et tabac\"),\n",
    "(\"466\",   \"Commerce de gros autres équipements industriels\"),\n",
    "(\"467\",   \"Autres commerces de gros spécialisés\"),\n",
    "(\"471\",   \"Commerce de détail en magasin non spécialisé\"),\n",
    "(\"472\",   \"Commerce de détail alimentaire en magasin spécialisé\"),\n",
    "(\"473\",   \"Commerce de détail de carburants en magasin spécialisé\"),\n",
    "(\"478\",   \"Commerce de détail sur éventaires et marchés\"),\n",
    "(\"551\",   \"Hôtels et hébergement similaire\"),\n",
    "(\"552\",   \"Hébergement touristique et autre hébergement courte durée\"),\n",
    "(\"5610A\", \"Restauration traditionnelle\"),\n",
    "(\"5610B\", \"Cafétérias et autres libres-services\"),\n",
    "(\"5610C\", \"Restauration rapide\"),\n",
    "(\"563\",    \"Débits de boissons\")\n",
    "]\n",
    "\n",
    "activites = [activites_annotees[i][0] for i in range(len(activites_annotees))]\n",
    "\n",
    "#Départements d'IDF\n",
    "dep = [\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\"]\n",
    "\n",
    "#Date minimale \n",
    "date_min = [2010,1,1]\n",
    "\n",
    "\n",
    "#Récupération des données depuis le cloud ssp cloud S3\n",
    "dates_select = [1980,1990,2000,2005,2010,2015,2017,2018,2019,2020,2021,2022,2023,2024]\n",
    "\n",
    "dfs_rne = dict()\n",
    "df_names = [(f\"df_{dates_select[i-1]}_{dates_select[i]}\",i) for i in range(1,len(dates_select))]\n",
    "\n",
    "url_dataRNE = ['https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1980_1990.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_1990_2000.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2000_2005.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2005_2010.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2010_2015.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2015_2017.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2017_2018.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2018_2019.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2019_2020.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2020_2021.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2021_2022.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2022_2023.parquet',\n",
    "'https://minio.lab.sspcloud.fr/guillaume176/diffusion/data_RNE/RNE_2023_2024.parquet']\n",
    "\n",
    "for names,i in tqdm(df_names):\n",
    "    print(f\"Récupération depuis le cloud {i}/13\")\n",
    "    url = url_dataRNE[i-1]\n",
    "    df = pd.read_parquet(url)\n",
    "    dfs_rne[names] = df\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Récupération des colonnes et création d'un nouveau data frame vide\n",
    "columns_rne = list(dfs_rne[df_names[0][0]].columns)\n",
    "idf_10_24 = pd.DataFrame(columns=columns_rne)\n",
    "\n",
    "#Filtrage par activites et département\n",
    "for names in tqdm(df_names):\n",
    "    print(\"Filtrage par département et activités\")\n",
    "    data = dfs_rne[names[0]]\n",
    "    data = data[data[\"codeAPE\"].str.startswith(tuple(activites)) & data[\"code_postal\"].str.startswith(tuple(dep))]\n",
    "    idf_10_24 = pd.concat([idf_10_24,data])\n",
    "    \n",
    "#Filtrage pour les dates de création après 2010-01-01 (inlcus)\n",
    "idf_10_24[\"date_creation\"] = pd.to_datetime(idf_10_24[\"date_creation\"])\n",
    "\n",
    "print(f\"Récupération depuis {date_min[0]}-{date_min[1]}-{date_min[2]}\")\n",
    "idf_10_24 = idf_10_24[idf_10_24[\"date_creation\"] >= datetime.datetime(date_min[0],date_min[1],date_min[2])]\n",
    "\n",
    "idf_10_24[\"dateRadiation\"] = idf_10_24[\"dateRadiation\"].apply(lambda x : \n",
    "    x if x not in [\"non-disp\",\"None\"] else pd.NaT)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#Récupération des colonnes et création d'un nouveau data frame vide\n",
    "columns_rne = list(dfs_rne[df_names[0][0]].columns)\n",
    "total = pd.DataFrame(columns=columns_rne)\n",
    "\n",
    "#Récupération complète dans un data frame\n",
    "print(\"Récupération de l'historique total\")\n",
    "for names in tqdm(df_names):\n",
    "    data = dfs_rne[names[0]]\n",
    "    total = pd.concat([total,data])\n",
    "\n",
    "\n",
    "total[\"date_creation\"] = pd.to_datetime(total[\"date_creation\"])\n",
    "total[\"dateRadiation\"] = total[\"dateRadiation\"].apply(lambda x : \n",
    "    x if x not in [\"non-disp\",\"None\"] else pd.NaT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a170011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNE_local_concurrents(df_p : pd.DataFrame, total_p : pd.DataFrame) -> pd.DataFrame :\n",
    "\n",
    "      total_p = total_p.loc[total_p[\"code_postal\"]!=\"non-disp\"]\n",
    "\n",
    "      #Récupération de l'indicatrice 1 si radiée 0 sinon\n",
    "      total_p[\"radié\"] = total_p[\"dateRadiation\"].apply(lambda x : 1 if x != None else 0)\n",
    "\n",
    "      #Conversion en date time de date_creation par sécurité\n",
    "      total_p[\"date_creation\"] = pd.to_datetime(total_p[\"date_creation\"])\n",
    "      df_p[\"date_creation\"] = pd.to_datetime(df_p[\"date_creation\"])\n",
    "\n",
    "      total_p[\"dateRadiation\"] = total_p[\"dateRadiation\"].apply(lambda x : \n",
    "      x if x not in [\"non-disp\",\"None\"] else pd.NaT)\n",
    "      total_p[\"dateRadiation\"] = pd.to_datetime(total_p[\"dateRadiation\"],errors=\"coerce\")\n",
    "\n",
    "      total_p[\"code_postal\"] = total_p[\"code_postal\"].astype(int)\n",
    "      df_p[\"code_postal\"] =  df_p[\"code_postal\"].astype(int)     \n",
    "\n",
    "      total = total_p.copy()\n",
    "      df = df_p.copy()\n",
    "\n",
    "      #Connexion DuckDB\n",
    "      con = duckdb.connect()\n",
    "\n",
    "      #Enregistrement des DataFrames pandas dans DuckDB\n",
    "      con.register(\"df\", df)        \n",
    "      con.register(\"total\", total)\n",
    "\n",
    "      con.execute(\"\"\"\n",
    "      CREATE OR REPLACE VIEW total_long AS\n",
    "      SELECT siren, date_creation,\n",
    "            radié AS rad,\n",
    "            codeAPE as ape,\n",
    "            code_postal as code\n",
    "      FROM total\n",
    "      WHERE radié IS NULL;\n",
    "      \"\"\")\n",
    "\n",
    "      #Requête principale pour le nombre de concurrents encore en poste sur le marché local\n",
    "      res = con.execute(f\"\"\"\n",
    "      SELECT\n",
    "      df.siren,\n",
    "\n",
    "      COUNT(DISTINCT t.siren) AS nb_local_concurrents\n",
    "\n",
    "      FROM df\n",
    "\n",
    "      LEFT JOIN total_long t\n",
    "      ON df.codeAPE = t.ape\n",
    "      AND df.code_postal = t.code\n",
    "      AND t.date_creation <= df.date_creation\n",
    "\n",
    "      GROUP BY df.siren\n",
    "      ORDER BY df.siren\n",
    "      \"\"\").df()\n",
    "\n",
    "      con.close()\n",
    "\n",
    "      return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c59454e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'non-disp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = idf_10_24\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m essai = \u001b[43mget_RNE_local_concurrents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_RNE_local_concurrents\u001b[39m\u001b[34m(df_p, total_p)\u001b[39m\n\u001b[32m     10\u001b[39m total_p[\u001b[33m\"\u001b[39m\u001b[33mdateRadiation\u001b[39m\u001b[33m\"\u001b[39m] = total_p[\u001b[33m\"\u001b[39m\u001b[33mdateRadiation\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \n\u001b[32m     11\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mnon-disp\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m pd.NaT)\n\u001b[32m     12\u001b[39m total_p[\u001b[33m\"\u001b[39m\u001b[33mdateRadiation\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(total_p[\u001b[33m\"\u001b[39m\u001b[33mdateRadiation\u001b[39m\u001b[33m\"\u001b[39m],errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m total_p[\u001b[33m\"\u001b[39m\u001b[33mcode_postal\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtotal_p\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcode_postal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m df_p[\u001b[33m\"\u001b[39m\u001b[33mcode_postal\u001b[39m\u001b[33m\"\u001b[39m] =  df_p[\u001b[33m\"\u001b[39m\u001b[33mcode_postal\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)     \n\u001b[32m     17\u001b[39m total = total_p.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/generic.py:6665\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6659\u001b[39m     results = [\n\u001b[32m   6660\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6661\u001b[39m     ]\n\u001b[32m   6663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6664\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6665\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6666\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/managers.py:449\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    447\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/internals/blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'non-disp'"
     ]
    }
   ],
   "source": [
    "df = idf_10_24\n",
    "essai = get_RNE_local_concurrents(df,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67911c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.loc[total[\"code_postal\"]==\"non-disp\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
